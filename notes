1. Pipeline можно определить через класс или используя функцию nvidia.dali.pipeline.Pipeline и конструкцию with. Для второго случаю так же надо будет определить
класс итератора. 
2. Я не нашел явного способа напрямую отправлять numpy массивы в пайплайн, но их можно использовать как аргументы во время инициализации итератора.
3. Возможно можно будет использовать Sequence Processing для обработки большого количества изображений сразу
(https://docs.nvidia.com/deeplearning/dali/user-guide/docs/examples/sequence_processing/video/video_reader_simple_example.html)
или интеграцию с пайплайном tensorflow. Четыре изображения размером 1024х1024 таким образом загружаются за 4.1484832763671875e-05 без random.shuffle и 
других изменений во время инициализации итератора.
4. Под with определяем агументации и другие изменения. Для построения пайплайна достаточно вызвать функцию pipeline.build().
5. Для того чтобы пропустить изобржаения достаточно вызвать функцию pipeline.run().
6. Для обработки новых данных надо заново инициализировать итератор.
7. Размер батча и количество загруженных изображений отдельные понятия. Если в итератор послать 128 изображений и указать батч размером 16, то функцию pipeline.run()
надо будет вызвать 8 раз, чтобы пройти через все данные.
8. Работа с несколькими GPU возможна через шардинг. https://docs.nvidia.com/deeplearning/dali/user-guide/docs/examples/general/multigpu.html#Sharding
